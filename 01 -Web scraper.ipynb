{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "536aa518",
   "metadata": {},
   "source": [
    "#### Lab - Web scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b67af0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T13:57:02.254490Z",
     "start_time": "2022-10-11T13:57:01.798033Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import random\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a669583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T13:57:03.042331Z",
     "start_time": "2022-10-11T13:57:03.035325Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://www.popvortex.com/music/charts/top-100-songs.php\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "414262fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T13:57:04.648819Z",
     "start_time": "2022-10-11T13:57:03.755738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(url)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cb6db83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T13:57:05.327004Z",
     "start_time": "2022-10-11T13:57:05.201472Z"
    }
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7353f8d",
   "metadata": {},
   "source": [
    "Building the song and artist lists from the scrapped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4775609",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T13:57:06.428449Z",
     "start_time": "2022-10-11T13:57:06.369439Z"
    }
   },
   "outputs": [],
   "source": [
    "#initialize empty lists\n",
    "position = []\n",
    "song = []\n",
    "artist = []\n",
    "\n",
    "num_iter = len(soup.select(\"div.chart-content.col-xs-12.col-sm-8 > p > cite\"))\n",
    "\n",
    "song_list = soup.select(\"div.chart-content.col-xs-12.col-sm-8 > p > cite\")\n",
    "art_list = soup.select(\"div.chart-content.col-xs-12.col-sm-8 > p > em\")\n",
    "\n",
    "# iterate through the result set and retrive all the data\n",
    "for i in range(num_iter):\n",
    "    song.append(song_list[i].get_text())\n",
    "    artist.append(art_list[i].get_text())\n",
    "    position.append(i+1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6f9360",
   "metadata": {},
   "source": [
    "#### Scraping/treating Genre and Release date\n",
    "The website stores all details on parent components but if it is a new release the first element is \n",
    "\"first release\", otherwise is the genre.\n",
    "So genre, release date are on 0 and 1 index regularly, 1 and 2 if it's a new release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d44e7f0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T13:57:11.386765Z",
     "start_time": "2022-10-11T13:57:09.449385Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list to store all elements\n",
    "multi = []\n",
    "\n",
    "for i in range(100):\n",
    "    multi.append(soup.select(\"#chart-position-\"+str(i+1)+\" > div.chart-content.col-xs-12.col-sm-8 > ul > li\"))\n",
    "\n",
    "# genre and release date sublists \n",
    "genre = []\n",
    "release = []\n",
    "\n",
    "# release date are on 0 and 1 index regularly, 1 and 2 if it's a new release\n",
    "for element in multi:\n",
    "    if element:\n",
    "        if element[0].get_text() == 'New Release':\n",
    "            genre.append(element[1].get_text().split('Genre: ')[1])\n",
    "            release.append(element[2].get_text().split('Release Date: ')[1])\n",
    "        else:\n",
    "            genre.append(element[0].get_text().split('Genre: ')[1])\n",
    "            release.append(element[1].get_text().split('Release Date: ')[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fe241e",
   "metadata": {},
   "source": [
    "#### Creating a new dataset with the previously generated lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "812409e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T14:02:38.834340Z",
     "start_time": "2022-10-11T14:02:38.817324Z"
    }
   },
   "outputs": [],
   "source": [
    "top100 = pd.DataFrame({\"rank\":position,\n",
    "                       \"song\":song,\n",
    "                       \"artist\":artist,\n",
    "                       \"genre\": genre,\n",
    "                       \"release\": release\n",
    "                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46b086e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T14:02:45.519599Z",
     "start_time": "2022-10-11T14:02:45.497579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Unholy</td>\n",
       "      <td>Sam Smith &amp; Kim Petras</td>\n",
       "      <td>Pop</td>\n",
       "      <td>2022.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Eagle (feat. KB)</td>\n",
       "      <td>Transformation Worship</td>\n",
       "      <td>Hip-Hop / Rap</td>\n",
       "      <td>2022.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm Good (Blue)</td>\n",
       "      <td>David Guetta &amp; Bebe Rexha</td>\n",
       "      <td>Dance</td>\n",
       "      <td>2022.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Everywhere</td>\n",
       "      <td>Fleetwood Mac</td>\n",
       "      <td>Rock</td>\n",
       "      <td>1987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>wait in the truck</td>\n",
       "      <td>HARDY &amp; Lainey Wilson</td>\n",
       "      <td>Country</td>\n",
       "      <td>2022.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Sand In My Boots</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>Country</td>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>No Se Va (En Vivo)</td>\n",
       "      <td>Grupo Frontera</td>\n",
       "      <td>Regional Mexicano</td>\n",
       "      <td>2022.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Perfectly Loved (feat. TobyMac)</td>\n",
       "      <td>Rachael Lampa</td>\n",
       "      <td>Christian &amp; Gospel</td>\n",
       "      <td>2022.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>How Far I'll Go</td>\n",
       "      <td>Auli'i Cravalho</td>\n",
       "      <td>Soundtrack</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Bedroom Singer</td>\n",
       "      <td>J.Fla</td>\n",
       "      <td>Alternative</td>\n",
       "      <td>2022.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank                             song                     artist  \\\n",
       "0      1                           Unholy     Sam Smith & Kim Petras   \n",
       "1      2                 Eagle (feat. KB)     Transformation Worship   \n",
       "2      3                  I'm Good (Blue)  David Guetta & Bebe Rexha   \n",
       "3      4                       Everywhere              Fleetwood Mac   \n",
       "4      5                wait in the truck      HARDY & Lainey Wilson   \n",
       "..   ...                              ...                        ...   \n",
       "95    96                 Sand In My Boots              Morgan Wallen   \n",
       "96    97               No Se Va (En Vivo)             Grupo Frontera   \n",
       "97    98  Perfectly Loved (feat. TobyMac)              Rachael Lampa   \n",
       "98    99                  How Far I'll Go            Auli'i Cravalho   \n",
       "99   100                   Bedroom Singer                      J.Fla   \n",
       "\n",
       "                 genre    year  \n",
       "0                  Pop  2022.0  \n",
       "1        Hip-Hop / Rap  2022.0  \n",
       "2                Dance  2022.0  \n",
       "3                 Rock  1987.0  \n",
       "4              Country  2022.0  \n",
       "..                 ...     ...  \n",
       "95             Country  2021.0  \n",
       "96   Regional Mexicano  2022.0  \n",
       "97  Christian & Gospel  2022.0  \n",
       "98          Soundtrack  2016.0  \n",
       "99         Alternative  2022.0  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top100.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f6a9d4",
   "metadata": {},
   "source": [
    "Making a year column in the top 100 dataset, and dropping the release date column so it wont mess up the concat with the other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f91b7741",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T14:02:44.224191Z",
     "start_time": "2022-10-11T14:02:44.202660Z"
    }
   },
   "outputs": [],
   "source": [
    "top100['year'] = pd.DatetimeIndex(top100['release']).year\n",
    "top100 = top100.drop(columns='release', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08fea09",
   "metadata": {},
   "source": [
    "#### Scrapping other sources and styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fadd3691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T14:03:08.467189Z",
     "start_time": "2022-10-11T14:03:08.459183Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to scrap the website based on begin year and end year\n",
    "def scrap_url(main, begin=1970, end= 2021):\n",
    "    \n",
    "    df_scrap = pd.DataFrame()\n",
    "    genre = ''\n",
    "    for year in range(begin, end+1):\n",
    "        #temporary containers for song and artist\n",
    "        song = []\n",
    "        artist = []\n",
    "        position = []\n",
    "        \n",
    "        # scraping individual link    \n",
    "        url = main + str(year)\n",
    "        response = requests.get(url)\n",
    "        print(year, 'request:',response.status_code)\n",
    "        \n",
    "        # parse & store html\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        # select table component from soup\n",
    "        tmp = soup.select('#myTable')\n",
    "        \n",
    "        if genre == '':\n",
    "            genre = soup.select('body > div.wrappercenter > div:nth-child(2) > nav > ol > li:nth-child(3) > a > span')[0].get_text()\n",
    "\n",
    "        #song soup\n",
    "        song_list = tmp[0].select(\".song a\")\n",
    "        #artist soup\n",
    "        art_list = tmp[0].select(\".artist\")\n",
    "\n",
    "        # iterate through the result set and retrive all the data\n",
    "        for i in range(len(art_list)):\n",
    "            song.append(song_list[i].get_text().replace('\\n',''))\n",
    "            artist.append(art_list[i].get_text().replace('\\n',''))\n",
    "            position.append(i+1)\n",
    "        \n",
    "        # respectful nap:\n",
    "        wait_time = random.randint(1,3)\n",
    "        sleep(wait_time)\n",
    "        \n",
    "        # creating a temporary dataset to add to the full set to be returned\n",
    "        df_list_tmp = pd.DataFrame({\"rank\":position,\n",
    "                       \"song\":song,\n",
    "                       \"artist\":artist,\n",
    "                       \"genre\": genre,\n",
    "                       \"year\": year,\n",
    "                      })\n",
    "        df_scrap = pd.concat([df_scrap, df_list_tmp], axis = 0)\n",
    "        \n",
    "    return df_scrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f158ec4c",
   "metadata": {},
   "source": [
    "#### Scraping multiple sources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e69ee1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Run only to rebuild the historical top 100 dataset\n",
    "# df = []\n",
    "\n",
    "# df.append(scrap_url('https://playback.fm/charts/rnb/'))\n",
    "# df.append(scrap_url('https://playback.fm/charts/country/'))\n",
    "# df.append(scrap_url('https://playback.fm/charts/rock/'))\n",
    "# df.append(scrap_url('https://playback.fm/charts/top-100-songs/'))\n",
    "\n",
    "# historic_df = pd.DataFrame()\n",
    "# for i in range(3):\n",
    "#     historic_df = pd.concat([historic_df, df[i]], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b57a79",
   "metadata": {},
   "source": [
    "#### Scraping more sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43952dff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T14:03:10.572035Z",
     "start_time": "2022-10-11T14:03:10.563027Z"
    }
   },
   "outputs": [],
   "source": [
    "def scrap_popvortex(country_list, full=False):\n",
    "    scrap = pd.DataFrame()\n",
    "    for url in country_list:\n",
    "        #initialize empty lists\n",
    "        position = []\n",
    "        song = []\n",
    "        artist = []\n",
    "        multi = []\n",
    "        # genre and release date sublists \n",
    "        genre = []\n",
    "        release = []\n",
    "\n",
    "        \n",
    "        if full:\n",
    "            response = requests.get('https://www.popvortex.com/music/' +str(url))\n",
    "        else:\n",
    "            response = requests.get('https://www.popvortex.com/music/' +str(url)+ '/top-songs.php')\n",
    "        print(url, 'status', response.status_code)\n",
    "\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        num_iter = len(soup.select(\"div.chart-content.col-xs-12.col-sm-8 > p > cite\"))\n",
    "        song_list = soup.select(\"div.chart-content.col-xs-12.col-sm-8 > p > cite\")\n",
    "        art_list = soup.select(\"div.chart-content.col-xs-12.col-sm-8 > p > em\")\n",
    "\n",
    "        # iterate through the result set and retrive all the data\n",
    "        for i in range(num_iter):\n",
    "            song.append(song_list[i].get_text())\n",
    "            artist.append(art_list[i].get_text())\n",
    "            position.append(i+1)\n",
    "\n",
    "        for i in range(100):\n",
    "            multi.append(soup.select(\"#chart-position-\"+str(i+1)+\" > div.chart-content.col-xs-12.col-sm-8 > ul > li\"))     \n",
    "\n",
    "        # release date are on 0 and 1 index regularly, 1 and 2 if it's a new release\n",
    "        for element in multi:\n",
    "            if element:\n",
    "                if element[0].get_text() == 'New Release':\n",
    "                    genre.append(element[1].get_text().split('Genre: ')[1])\n",
    "                    release.append(element[2].get_text().split('Release Date: ')[1])\n",
    "                else:\n",
    "                    genre.append(element[0].get_text().split('Genre: ')[1])\n",
    "                    release.append(element[1].get_text().split('Release Date: ')[1])\n",
    "\n",
    "        tmp = pd.DataFrame({\"rank\":position,\n",
    "                               \"song\":song,\n",
    "                               \"artist\":artist,\n",
    "                               \"genre\": genre,\n",
    "                               \"release\": release\n",
    "                              })\n",
    "        \n",
    "        scrap = pd.concat([scrap, tmp], axis = 0)\n",
    "    \n",
    "    return scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84d37a66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T14:04:05.221501Z",
     "start_time": "2022-10-11T14:03:16.085656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "austria status 200\n",
      "belgium status 200\n",
      "canada status 200\n",
      "finland status 200\n",
      "germany status 200\n",
      "greece status 200\n",
      "india status 200\n",
      "ireland status 200\n",
      "italy status 200\n",
      "mexico status 200\n",
      "netherlands status 200\n",
      "norway status 200\n",
      "philippines status 200\n",
      "poland status 200\n",
      "south-africa status 200\n",
      "spain status 200\n",
      "sweden status 200\n",
      "switzerland status 200\n"
     ]
    }
   ],
   "source": [
    "countries = ['austria', 'belgium', 'canada', 'finland', 'germany', 'greece', 'india', 'ireland', 'italy', \n",
    "            'mexico', 'netherlands', 'norway', 'philippines', 'poland', 'south-africa', 'spain', 'sweden', 'switzerland' ]\n",
    "\n",
    "# top100 in various countries \n",
    "tops = scrap_popvortex(countries)\n",
    "tops['year'] = 2022\n",
    "tops = tops.drop(columns='release', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ee6241",
   "metadata": {},
   "source": [
    "##### Saving our scraped data to a csv file for further work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090e137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# historic_df.to_csv('Top 100 songs 1970-2021.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df690da4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T14:04:39.459819Z",
     "start_time": "2022-10-11T14:04:39.441109Z"
    }
   },
   "outputs": [],
   "source": [
    "historic_df = pd.read_csv('Data/Top 100 songs 1970-2021.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6f1a08",
   "metadata": {},
   "source": [
    "#### Joining Top 100 2022 songs, with 2021 top songs by type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3e3d2a",
   "metadata": {},
   "source": [
    "Concatenating the lists into a bigger song dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3a8249b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T14:04:44.879242Z",
     "start_time": "2022-10-11T14:04:44.871407Z"
    }
   },
   "outputs": [],
   "source": [
    "top_list = pd.concat([top100, tops ,historic_df[historic_df['year']==2021]], axis = 0)\n",
    "top_list = top_list.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e39b1f19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T15:40:27.791662Z",
     "start_time": "2022-10-11T15:40:27.774646Z"
    }
   },
   "outputs": [],
   "source": [
    "top_list.drop_duplicates(subset='song', keep='first').to_csv('Top 100 songs worldwide.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
